{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ad-hoc Pulse Shape Simulation Using Cyclic Positional U-Net (CPU-Net)\n",
    "- This is the source code of training and validating the performance of CPU-Net\n",
    "- This code should run on a standard python environment with PyTorch installed. The PyTorch version is 1.9.0, Nividia A100 GPU is used.\n",
    "    - we recommend installing a small gadget `tqdm` to monitor the time/progress of `for` loops. Installation can be done with `pip install tqdm --user`\n",
    "    - If the user do not wish to install `tqdm`, please delete the import code and tdqm() wrapper\n",
    "- This repository only contains the script of the model, training data has to be downloaded separately at [here](https://drive.google.com/file/d/1JcgQy6snavgcRetFAGl0QM3OAmPTqKqt/view?usp=sharing).\n",
    "- Once downloaded, please unzip it and dump it into the same folder with this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import torchsnooper\n",
    "from scipy import signal\n",
    "from torch import nn, einsum\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Loading CPU-Net and support functions\n",
    "from tools import get_ca, get_tail_slope, inf_train_gen, LambdaLR, weights_init_normal\n",
    "from dataset import SplinterDataset, SEQ_LEN, LSPAN, RSPAN\n",
    "from network import PositionalUNet, RNN\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "- This function loads the siggen simulation and detector pulse dataset, splitting them into training and validation data loader with 7:3 ratio\n",
    "- Simulated pulses are generated in Siggen\n",
    "- Detector pulses are collected from a local Ge detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "def load_data(batch_size):\n",
    "    dataset = SplinterDataset(\"DetectorPulses.pickle\", \"SimulatedPulses.pickle\")\n",
    "\n",
    "    validation_split = .3\n",
    "    shuffle_dataset = True\n",
    "    random_seed= 42222\n",
    "    indices = np.arange(len(dataset))\n",
    "\n",
    "    if shuffle_dataset :\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    split = int(validation_split*len(dataset))\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    dataset.set_raw_waveform(False)\n",
    "    train_loader = data_utils.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler,  drop_last=True)\n",
    "    test_loader = data_utils.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler,  drop_last=True)\n",
    "\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Training\n",
    "- Define global parameter for the training\n",
    "    - DEVICE: the device for CPU-Net training, use GPU if GPU node is found, otherwise use CPU\n",
    "    - BATCH_SIZE: batch size, each batch is drawn from the infinite train generator\n",
    "    - ITERS: how many batch to train\n",
    "    - DECAY: learning rate decay\n",
    "    - LRATE: learning rate\n",
    "    - target_real: a vector of 1, used for GAN discriminator training\n",
    "    - target_fake: a vector of 0, used for GAN discriminator training\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "BATCH_SIZE = 16\n",
    "ITERS = 3001\n",
    "DECAY = 500\n",
    "LRATE =1e-3\n",
    "target_real = torch.ones(BATCH_SIZE,1).to(DEVICE)\n",
    "target_fake = torch.zeros(BATCH_SIZE,1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create infinite train generator. This generator can be called an infinite amount of time to draw from training dataset (with repetition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_data(BATCH_SIZE)\n",
    "data = inf_train_gen(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create network structures and feed them into the DEVICE defined above\n",
    "    - A: Detector Pulses\n",
    "    - B: Simulated Pulses\n",
    "    - BtoA: Ad-hoc Translation Network (Simulation to Data)\n",
    "    - AtoB: Inverse Ad-hoc Translation Network (Data to Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_A2B = PositionalUNet()\n",
    "netG_B2A = PositionalUNet()\n",
    "netD_A = RNN().apply(weights_init_normal)\n",
    "netD_B = RNN().apply(weights_init_normal)\n",
    "netG_A2B.to(DEVICE)\n",
    "netG_B2A.to(DEVICE)\n",
    "netD_A.to(DEVICE)\n",
    "netD_B.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create loss function and set up optimizer\n",
    "    - BCELoss for discriminator\n",
    "    - WFDist is a special L1loss where additional weight is added to the rising and falling edge of the waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WFDist(nn.Module):\n",
    "    '''\n",
    "    Waveform Distance, this is a special type of L1 loss which gives more weight to the\n",
    "    rising and falling edge of each pulse\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(WFDist, self).__init__()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.weight = torch.tensor([2.0]*LSPAN+[10.0]*150+[5.0]*(RSPAN-150)).to(DEVICE)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        loss_out = 0.0\n",
    "        for i in range(x1.size(0)):\n",
    "            loss_out += self.criterion(x1[i].view(-1)*self.weight, x2[i].view(-1)*self.weight)#/self.weight.sum()\n",
    "        return loss_out/x1.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = nn.BCELoss().to(DEVICE)\n",
    "criterion_cycle = WFDist().to(DEVICE)\n",
    "criterion_identity = WFDist().to(DEVICE)\n",
    "\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),lr=LRATE, betas=(0.5, 0.999))\n",
    "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=LRATE, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=LRATE, betas=(0.5, 0.999))\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(ITERS, 0, DECAY).step)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(ITERS, 0, DECAY).step)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(ITERS, 0, DECAY).step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for iteration in tqdm(range(ITERS)):\n",
    "    netG_A2B.train()\n",
    "    netG_B2A.train()\n",
    "\n",
    "    #########################\n",
    "    # A: DetectorPulses\n",
    "    # B: Simulated Pulses\n",
    "    #########################\n",
    "    \n",
    "    real_A, real_B = next(data)\n",
    "    real_A = real_A.to(DEVICE).float()\n",
    "    real_B = real_B.to(DEVICE).float()\n",
    "\n",
    "    ###### Generators A2B and B2A ######\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    # Identity loss\n",
    "    # G_A2B(B) should equal B if real B is fed\n",
    "    same_B = netG_A2B(real_B)\n",
    "    loss_identity_B = criterion_identity(same_B, real_B)*5\n",
    "    # G_B2A(A) should equal A if real A is fed\n",
    "    same_A = netG_B2A(real_A)\n",
    "    loss_identity_A = criterion_identity(same_A, real_A)*5\n",
    "\n",
    "    # GAN loss\n",
    "    fake_B = netG_A2B(real_A)\n",
    "    pred_fake = netD_B(fake_B)\n",
    "    # loss_GAN_A2B = pred_fake.mean()\n",
    "    # loss_GAN_A2B.backward(target_real)\n",
    "    loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "    fake_A = netG_B2A(real_B)\n",
    "    pred_fake = netD_A(fake_A)\n",
    "    # loss_GAN_B2A = pred_fake.mean()\n",
    "    # rand = torch.tensor(np.random.rand()).to(DEVICE)*0.5+0.5\n",
    "    # random_real = random_real[torch.randperm(random_real.size(0))]\n",
    "    loss_GAN_B2A = criterion_GAN(pred_fake,target_real)\n",
    "\n",
    "    # Cycle loss\n",
    "    recovered_A = netG_B2A(fake_B)\n",
    "    loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
    "\n",
    "    recovered_B = netG_A2B(fake_A)\n",
    "    loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
    "\n",
    "    # Total loss\n",
    "    loss_G = loss_identity_A + loss_identity_B + loss_cycle_ABA + loss_cycle_BAB + loss_GAN_A2B + loss_GAN_B2A\n",
    "    loss_G.backward()\n",
    "\n",
    "    optimizer_G.step()\n",
    "    ###### Discriminator A (Detector Pulses) ######\n",
    "    optimizer_D_A.zero_grad()\n",
    "\n",
    "    # Real loss\n",
    "    pred_real = netD_A(real_A)\n",
    "    loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "    # Fake loss\n",
    "    pred_fake = netD_A(fake_A.detach())\n",
    "    loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "\n",
    "    # Total loss\n",
    "    loss_D_A = loss_D_real + loss_D_fake\n",
    "    loss_D_A.backward()\n",
    "\n",
    "    optimizer_D_A.step()\n",
    "    ###### Discriminator B (Simulated Pulses) ######\n",
    "    optimizer_D_B.zero_grad()\n",
    "\n",
    "    # Real loss\n",
    "    pred_real = netD_B(real_B)\n",
    "    loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "    # Fake loss\n",
    "    pred_fake = netD_B(fake_B.detach())\n",
    "    loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "\n",
    "    # Total loss\n",
    "    loss_D_B = loss_D_real + loss_D_fake\n",
    "    loss_D_B.backward()\n",
    "\n",
    "\n",
    "\n",
    "    optimizer_D_B.step()\n",
    "    # ###################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save trained ATN and IATN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netG_B2A.state_dict(), 'ATN.pt')\n",
    "torch.save(netG_A2B.state_dict(), 'IATN.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Validation and Plot\n",
    "- Load the trained ATN into the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ATN = PositionalUNet()\n",
    "ATN.to(DEVICE)\n",
    "pretrained_dict = torch.load('ATN.pt')\n",
    "model_dict = ATN.state_dict()\n",
    "model_dict.update(pretrained_dict) \n",
    "ATN.load_state_dict(pretrained_dict)\n",
    "ATN.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read a single batch from the test loader, translating it through the ATN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf, wf_deconv, _ = next(iter(test_loader))\n",
    "wf = wf.to(DEVICE)\n",
    "wf_deconv = wf_deconv.to(DEVICE)\n",
    "outputs  = ATN(wf_deconv)\n",
    "iwf = 2 # the ith waveform in the batch to plot\n",
    "detector_pulse = wf[iwf,0,:].cpu().data.numpy().flatten()\n",
    "simulated_pulse = wf_deconv[iwf,0,:].cpu().data.numpy().flatten()\n",
    "translated_pulse = outputs[iwf,0,:].cpu().data.numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot simulated pulses, data pulses and translated pulses in the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 7))\n",
    "plt.plot(detector_pulse, label=\"Data Pulse\",alpha=0.3, color=\"magenta\", linestyle=\":\",linewidth = 4)\n",
    "plt.plot(simulated_pulse, label=\"Simulated Pulse\",alpha=0.7, color=\"red\", linewidth = 3)\n",
    "plt.plot(translated_pulse, label=\"ATN Output\",color=\"dodgerblue\", linewidth = 2)\n",
    "plt.axvspan(xmin=300,xmax=358,alpha=0.2,color=\"grey\", label=\"Preamp Integration\")\n",
    "plt.axvspan(xmin=358,xmax=800,alpha=0.1,color=\"cyan\",label=\"RC Discharge\")\n",
    "plt.xticks([], [])\n",
    "plt.yticks([], [])\n",
    "plt.xlabel(\"Time Sample [ns]\")\n",
    "plt.ylabel(\"ADC Counts [a.u.]\")\n",
    "# ax_main.plot(orwf, label=\"Data->Siggen\",alpha=0.3,color=\"green\", linewidth = 5)\n",
    "# plt.gca().get_xaxis().set_visible(False)\n",
    "# plt.gca().get_yaxis().set_visible(False)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlim(200, 600)\n",
    "plt.savefig(\"ATN.png\",dpi=200)\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obtain the critical reconstruction parameters of each waveform by looping through the test dataset\n",
    "    - `ca`: maximal current amplitude\n",
    "    - `ts`: tail slope\n",
    "- Note that this code is slow, mainly because of the current amplitdue calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = []\n",
    "gan_ts = []\n",
    "ca = []\n",
    "gan_ca = []\n",
    "sim_ca = []\n",
    "for wf, wf_deconv,rawwf in tqdm(test_loader):\n",
    "    bsize = wf.size(0)\n",
    "    gan_wf = netG_B2A(wf_deconv.to(DEVICE).float())\n",
    "    for iwf in range(bsize):\n",
    "        datawf = wf[iwf,0].cpu().numpy().flatten()\n",
    "        siggenwf = wf_deconv[iwf,0].cpu().numpy().flatten()\n",
    "        transfer_wf = gan_wf[iwf,0].detach().cpu().numpy().flatten()\n",
    "        ts.append(get_tail_slope(datawf))\n",
    "        gan_ts.append(get_tail_slope(transfer_wf))\n",
    "        ca.append(get_ca(datawf))\n",
    "        gan_ca.append(get_ca(transfer_wf))\n",
    "        sim_ca.append(get_ca(siggenwf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plotting the normalized tail slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "ts = np.array(ts)\n",
    "gan_ts =np.array(gan_ts)\n",
    "mean,std = norm.fit(select_quantile(ts))\n",
    "rg = np.linspace(-4,16,50)\n",
    "plt.hist((np.array(ts)-mean)/std,bins=rg,histtype=\"step\",linewidth=2,density=False,color=\"dodgerblue\",label=\"Detector Pulse\")\n",
    "mean,std= norm.fit(select_quantile(gan_ts))\n",
    "plt.hist((np.array(gan_ts)-mean)/std,bins=rg,histtype=\"step\",linewidth=2,density=False,color=\"magenta\",label=\"ATN Output Pulse\")\n",
    "plt.axvline(x=0,color=\"deeppink\",linewidth=3,label=\"Simulated Pulse\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"# of Waveforms/ 0.02 [a.u.]\")\n",
    "plt.xlabel(\"Normalized Tail Slope [a.u.]\")\n",
    "plt.savefig(\"tailslope.png\",dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plotting the maximal current amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "rg = np.linspace(0.05,0.12,50)\n",
    "plt.hist(ca,bins=rg,label=\"Detector Pulse\",histtype=\"step\",linewidth=2,color=\"dodgerblue\")\n",
    "plt.hist(gan_ca,bins=rg,label=\"ATN Output Pulse\",alpha=0.1,color=\"magenta\")\n",
    "plt.hist(sim_ca,bins=rg,label=\"Simulated Pulse\",linewidth=2,histtype=\"step\",color=\"deeppink\")\n",
    "plt.xlabel(\"Current Amplitude [Normalized ADC Count / 100 ns]\")\n",
    "plt.ylabel(\"# of Events / 0.001 Current Amplitude\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.savefig(\"current_amp.png\",dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.9.0",
   "language": "python",
   "name": "pytorch-1.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
